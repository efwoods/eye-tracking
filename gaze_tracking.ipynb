{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef008aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pynput.mouse import Controller\n",
    "import screeninfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d59ec51",
   "metadata": {},
   "source": [
    "# Eye Gaze Mouse Movement Open Source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51041c0",
   "metadata": {},
   "source": [
    "## Example of ScreenReading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a3906b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor: HDMI-0\n",
      "Width: 3440\n",
      "Height: 1440\n",
      "Position: 0, 0\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "monitors = screeninfo.get_monitors()\n",
    "\n",
    "for monitor in monitors:\n",
    "    print(f\"Monitor: {monitor.name}\")\n",
    "    print(f\"Width: {monitor.width}\")\n",
    "    print(f\"Height: {monitor.height}\")\n",
    "    print(f\"Position: {monitor.x}, {monitor.y}\")\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b404dac",
   "metadata": {},
   "source": [
    "## Code to list active webcam devices and preview webcam feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1b239e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_webcams():\n",
    "    \"\"\"List all active webcam devices connected to the system\n",
    "    \"\"\"\n",
    "    available_cameras = []\n",
    "    for i in range(10):\n",
    "        cap = cv2.VideoCapture(i)\n",
    "        if cap.isOpened():\n",
    "            available_cameras.append(i)\n",
    "        cap.release()\n",
    "    return available_cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f2d4cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_webcam(device_index=0):\n",
    "    \"\"\"Preview the webcam feed from a specific device.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    device_index : int, optional\n",
    "        This is the index of the device, by default 0\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(device_index)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Unable to open webcam at index {device_index}\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "    \n",
    "        cv2.imshow(f\"Webcam Preview - Device {device_index}\", frame)\n",
    "\n",
    "        # Press 'q' to exit the preview\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d108827b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active webcams\n",
      "[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@5.285] global cap_v4l.cpp:913 open VIDEOIO(V4L2:/dev/video1): can't open camera by index\n",
      "[ERROR:0@5.285] global obsensor_uvc_stream_channel.cpp:158 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@5.285] global cap_v4l.cpp:913 open VIDEOIO(V4L2:/dev/video2): can't open camera by index\n",
      "[ERROR:0@5.286] global obsensor_uvc_stream_channel.cpp:158 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@5.286] global cap_v4l.cpp:913 open VIDEOIO(V4L2:/dev/video3): can't open camera by index\n",
      "[ERROR:0@5.286] global obsensor_uvc_stream_channel.cpp:158 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@5.286] global cap_v4l.cpp:913 open VIDEOIO(V4L2:/dev/video4): can't open camera by index\n",
      "[ERROR:0@5.286] global obsensor_uvc_stream_channel.cpp:158 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@5.286] global cap_v4l.cpp:913 open VIDEOIO(V4L2:/dev/video5): can't open camera by index\n",
      "[ERROR:0@5.286] global obsensor_uvc_stream_channel.cpp:158 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@5.286] global cap_v4l.cpp:913 open VIDEOIO(V4L2:/dev/video6): can't open camera by index\n",
      "[ERROR:0@5.286] global obsensor_uvc_stream_channel.cpp:158 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@5.286] global cap_v4l.cpp:913 open VIDEOIO(V4L2:/dev/video7): can't open camera by index\n",
      "[ERROR:0@5.286] global obsensor_uvc_stream_channel.cpp:158 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@5.286] global cap_v4l.cpp:913 open VIDEOIO(V4L2:/dev/video8): can't open camera by index\n",
      "[ERROR:0@5.287] global obsensor_uvc_stream_channel.cpp:158 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@5.287] global cap_v4l.cpp:913 open VIDEOIO(V4L2:/dev/video9): can't open camera by index\n",
      "[ERROR:0@5.287] global obsensor_uvc_stream_channel.cpp:158 getStreamChannelGroup Camera index out of range\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(webcams)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Preview the first available webcam\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mpreview_webcam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwebcams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo active webcam devices found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m, in \u001b[0;36mpreview_webcam\u001b[0;34m(device_index)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to grab frame\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# List active webcam devices\n",
    "print(\"Active webcams\")\n",
    "webcams = list_webcams()\n",
    "if webcams:\n",
    "    print(webcams)\n",
    "    # Preview the first available webcam\n",
    "    preview_webcam(webcams[0])\n",
    "else:\n",
    "    print(\"No active webcam devices found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7109be",
   "metadata": {},
   "source": [
    "## Example code to track eye gaze and move the mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e49eb541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 11:58:11.475205: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-14 11:58:11.484149: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747238291.493816  423018 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747238291.496698  423018 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747238291.504693  423018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747238291.504703  423018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747238291.504704  423018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747238291.504705  423018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-14 11:58:11.507531: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from pynput.mouse import Controller\n",
    "import time\n",
    "import sys\n",
    "import screeninfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bdeb70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1747238294.018778  423018 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1747238294.065340  423158 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 550.144.03), renderer: NVIDIA GeForce RTX 2080 Ti/PCIe/SSE2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1747238294.071232  423156 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1747238294.081085  423144 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# ------------------\n",
    "# 1. Setup\n",
    "# ------------------\n",
    "\n",
    "mp_face = mp.solutions.face_mesh\n",
    "face_mesh = mp_face.FaceMesh(static_image_mode=False, refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mouse = Controller()\n",
    "\n",
    "# Acquiring the actual screen display size\n",
    "monitor = screeninfo.get_monitors()[0]\n",
    "SCREEN_W, SCREEN_H = monitor.width, monitor.height\n",
    "\n",
    "# Eye landmarks indices for iris center (MediaPipe FaceMesh)\n",
    "# Left iris center is average of landmarks 473, 474, 475, 476\n",
    "LEFT_IRIS_IDX = [473, 474, 475, 476]\n",
    "RIGHT_IRIS_IDX = [468, 469, 470, 471]\n",
    "\n",
    "CAL_POINTS_NORM = [\n",
    "    (0.1, 0.1), # top-left\n",
    "    (0.9, 0.1), # top-right\n",
    "    (0.1, 0.9), # bottom-left\n",
    "    (0.9, 0.9), # bottom-right\n",
    "    (0.5, 0.5)  # center\n",
    "]\n",
    "\n",
    "def get_iris_center(landmarks, idx_list, img_w, img_h):\n",
    "    xs = [landmarks[i].x * img_w for i in idx_list]\n",
    "    yx = [landmarks[i].y * img_h for i in idx_list]\n",
    "    return np.mean(xs), np.mean(ys)\n",
    "\n",
    "# --------------\n",
    "# 2. Calibration\n",
    "# --------------\n",
    "def calibrate(cap):\n",
    "    cal_src = [] # [ [iris_x, iris_y], ... ]\n",
    "    cal_dst = [] # [ [screen_x, screen_y], ... ]\n",
    "    for(nx, ny) in CAL_POINTS_NORM:\n",
    "        # Draw fulll-screen point\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                sys.exit(\"Webcam not available\")\n",
    "            h, w, _ = frame.shape\n",
    "            # draw calibration point\n",
    "            px, py = int(nx*w), int(ny*h)\n",
    "            disp = frame.copy()\n",
    "            cv2.circle(disp, (px, py), 20, (0, 255, 0), -1)\n",
    "            cv2.putText(disp, \"Press Space to record here\", (30, 30), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "            cv2.imshow(\"Calibration\", disp)\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == 32: # space bar\n",
    "                # capture a frame, detect face\n",
    "                rgb = cv2.cvtColor(frame, cv2.COLOR_BAYER_BG2BGR)\n",
    "                res = face_mesh.process(rgb)\n",
    "                if not res.multi_face_landmarks:\n",
    "                    continue # try again until face is found\n",
    "                lm = res.multi_face_landmarks[0].landmark\n",
    "                # average both eyes\n",
    "                lx, ly = get_iris_center(lm, LEFT_IRIS_IDX, w, h)\n",
    "                rx, ry = get_iris_center(lm, RIGHT_IRIS_IDX, w, h)\n",
    "                ix, iy = (lx+rx)/2, (ly+ry)/2\n",
    "                cal_src.append([ix, iy])\n",
    "                cal_dst.append([nx*SCREEN_W, ny*SCREEN_H])\n",
    "                break\n",
    "            if key == 27:  # Escape quits\n",
    "                sys.exit(\"Calibration aborted\")\n",
    "    cv2.destroyWindow(\"Calibration\")\n",
    "    return np.array(cal_src), np.array(cal_dst)\n",
    "\n",
    "\n",
    "# ------------------\n",
    "# 3. Compute mapping\n",
    "# ------------------\n",
    "\n",
    "def solve_mapping(src, dst):\n",
    "    # Want a mapping: [ix, iy, 1] @ M = [sx, sy]\n",
    "    A = np.hstack([src, np.ones((src.shape[0], 1))]) # shape: N x 3\n",
    "    # solve least squares for M: shape 3x2\n",
    "    M, _, _, _ = np.linalg.lstsq(A, dst, rcond=None) \n",
    "    return M # [ix, iy, 1] @ M = [screen_x, screen_y]\n",
    "\n",
    "# ------------------------------------------\n",
    "# 4. Drive real-time mouse-movement via gaze\n",
    "# ------------------------------------------\n",
    "def drive_mouse_via_gaze(cap, M):\n",
    "    last_x, last_y = SCREEN_W/2, SCREEN_H/2\n",
    "    alpha = 0.3 # smoothing factor\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        h, w, _ = frame.shape\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BAYER_BG2BGR)\n",
    "        res = face_mesh.process(rgb)\n",
    "        if res.multi_face_landmarks:\n",
    "            lm = res.multi_face_landmarks[0].landmark\n",
    "            lx, ly = get_iris_center(lm, LEFT_IRIS_IDX, w, h)\n",
    "            rx, ry = get_iris_center(lm, RIGHT_IRIS_IDX, w, h)\n",
    "            ix, iy = (lx+rx)/2, (ly+ry)/2\n",
    "            # map to screen (affine)\n",
    "            src_v = np.array([ix, iy, 1.0])\n",
    "            sx, sy = src_v @ M\n",
    "            # smooth\n",
    "            cx = last_x +alpha*(sx - last_x)\n",
    "            cy = last_y + alpha*(sy - last_y)\n",
    "            mouse_position = (cx, cy)\n",
    "            last_x, last_y = cx, cy\n",
    "        \n",
    "        # OPTIONAL: display camera feed\n",
    "        cv2.imshow(\"Mouse->Gaze\", frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27: # Esc to quit\n",
    "            break\n",
    "\n",
    "\n",
    "# -------\n",
    "# 4. Main\n",
    "# -------\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        sys.exit(\"Cannot open camera\")\n",
    "    print(\"Starting calibration...\")\n",
    "    src, dst = calibrate(cap)\n",
    "    print(\"Calibrating mapping...\")\n",
    "    M = solve_mapping(src, dst)\n",
    "    print(\"Starting gaze-controlled mouse. Press Esc to exit.\")\n",
    "    drive_mouse_via_gaze(cap, M)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1895c047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting calibration...\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) /io/opencv/modules/imgproc/src/demosaicing.cpp:1778: error: (-215:Assertion failed) scn == 1 && (dcn == 3 || dcn == 4) in function 'demosaicing'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 126\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m     sys\u001b[38;5;241m.\u001b[39mexit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot open camera\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting calibration...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 126\u001b[0m src, dst \u001b[38;5;241m=\u001b[39m \u001b[43mcalibrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalibrating mapping...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    128\u001b[0m M \u001b[38;5;241m=\u001b[39m solve_mapping(src, dst)\n",
      "Cell \u001b[0;32mIn[3], line 53\u001b[0m, in \u001b[0;36mcalibrate\u001b[0;34m(cap)\u001b[0m\n\u001b[1;32m     50\u001b[0m key \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m32\u001b[39m: \u001b[38;5;66;03m# space bar\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# capture a frame, detect face\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     rgb \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BAYER_BG2BGR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     res \u001b[38;5;241m=\u001b[39m face_mesh\u001b[38;5;241m.\u001b[39mprocess(rgb)\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m res\u001b[38;5;241m.\u001b[39mmulti_face_landmarks:\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/demosaicing.cpp:1778: error: (-215:Assertion failed) scn == 1 && (dcn == 3 || dcn == 4) in function 'demosaicing'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ebce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
